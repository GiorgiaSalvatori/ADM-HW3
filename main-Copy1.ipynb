{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.8.tar.gz (981 kB)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from langdetect) (1.14.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993196 sha256=1530ad731e6b7217fd5c05ee7962ee368d2f5eb3ecc3e24166a7dae28947a790\n",
      "  Stored in directory: c:\\users\\francesco\\appdata\\local\\pip\\cache\\wheels\\59\\f6\\9d\\85068904dba861c0b9af74e286265a08da438748ee5ae56067\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.8\n",
      "Collecting selenium\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "## installation of libraries\n",
    "!pip install langdetect\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "\n",
    "import urllib\n",
    "from langdetect import detect\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***1. Data collection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calling selenium firefox driver\n",
    "driver = webdriver.Firefox(executable_path = r'D:\\chrome\\geckodriver-v0.26.0-win64\\geckodriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create dataframe with links of each book\n",
    "df = pd.DataFrame(columns = ['Href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Get the list of books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [43:41<00:00,  8.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# We will go page by page and and store links in dataframe\n",
    "href = []\n",
    "for i in tqdm(range(1, 301)):\n",
    "    driver.get('https://www.goodreads.com/list/show/1.Best_Books_Ever?page=' + str(i))\n",
    "    driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    for url in soup.find_all('a', {'class':'bookTitle'}):\n",
    "        string = 'https://www.goodreads.com/' + str(url.get('href'))\n",
    "        href.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Href'] = href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Href'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save dataframe\n",
    "df.to_csv('updated_url_30000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2Zy3F8rE4pO"
   },
   "outputs": [],
   "source": [
    "# let's load the links we have from dataframe\n",
    "df=pd.read_csv(r'/content/drive/MyDrive/La_sapienza/ADM/updated_url_30000.csv')\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYuehG1y60DT"
   },
   "source": [
    "#### So due to space constraint we have downloaded 10000 pages each and then we have merged it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irzM0N5bFV-g",
    "outputId": "7a911185-7476-46f9-a321-cde6200b667f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1264it [12:53,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, link in tqdm(enumerate(df['Href'][10001:20000])):\n",
    "    urllib.request.urlretrieve (link, r\"/content/drive/MyDrive/La_sapienza/ADM/html_data/{}_book_{}.html\".format(link.split('/')[-1],str(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3B-x77ovE41M"
   },
   "outputs": [],
   "source": [
    "# let's create dataframe where we are going to save every thing we are going to crawl from html pages\n",
    "df = pd.DataFrame(columns  = ['bookTitle','bookSeries', 'bookAuthors', 'ratingValue', 'Plot', 'ratingCount','reviewCount' ,'NumberofPages',\n",
    "                              'PublishingDate', 'Characters','Setting', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "go0zNxbQE43j",
    "outputId": "1388d4ea-5e64-4054-9100-e58ac82bbfc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [15:29,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "bookTitle = []\n",
    "bookSeries = []\n",
    "bookAuthors = []\n",
    "ratingValue = []\n",
    "Plot = []\n",
    "ratingCount = []\n",
    "reviewCount = []\n",
    "NumberofPages = []\n",
    "PublishingDate = []\n",
    "Characters = []\n",
    "Setting = []\n",
    "url = []\n",
    "\n",
    "count_r =  1\n",
    "for path, directories, files in os.walk(r'/content/drive/MyDrive/La_sapienza/ADM/html_data'):\n",
    "  for idx, file in tqdm(enumerate(files[8000:])):\n",
    "    # if count<5:\n",
    "    #   print(path +'/'+ file)\n",
    "    paths = path + '/' + file\n",
    "    soup = BeautifulSoup(open(paths), features='lxml')\n",
    "    #Plot  \n",
    "    txt = ''\n",
    "    # plot_text = soup.find_all('div', id = 'description')[0].contents[3].contents[0]\n",
    "    try:\n",
    "      txt = ''\n",
    "      for k in soup.find_all('div', id = 'description')[0].find_all('span'):\n",
    "        txt = txt + ' ' + k.text\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    if len(txt) > 0 and detect(txt) == 'en' :  # check if lang of plot is english or not\n",
    "      Plot.append(txt)\n",
    "      \n",
    "      #bookTitle\n",
    "      # booktitle= soup.find_all('h1')[0].contents[0]\n",
    "      try:\n",
    "        booktitle = soup.find('h1', {'id': 'bookTitle'}).text.strip()  \n",
    "        bookTitle.append(booktitle)\n",
    "      except:\n",
    "        bookTitle.append(np.nan)\n",
    "\n",
    "      #bookSeries\n",
    "      try:\n",
    "        bkseries = soup.find('h2', {'id': 'bookSeries'}).find('a', {'class':'greyText'}).text.strip()\n",
    "        bookSeries.append(bkseries)\n",
    "      except:\n",
    "        bookSeries.append(np.nan)\n",
    "\n",
    "\n",
    "      #bookAuthors\n",
    "      try:\n",
    "        bauthor = []\n",
    "        for el in soup.find_all('a', class_='authorName'):\n",
    "            bauthor.append(el.string)\n",
    "        bookAuthors.append(\", \".join(bauthor))\n",
    "      except:\n",
    "        bookAuthors.append(np.nan)\n",
    "\n",
    "      #ratingValue\n",
    "      try:\n",
    "        rv = soup.find('span', {'itemprop':'ratingValue'}).text.strip()\n",
    "        # rv = soup.find_all('span', itemprop= 'ratingValue')[0].contents[0]\n",
    "        ratingValue.append((' '.join(rv)))\n",
    "      except:\n",
    "        ratingValue.append(np.nan)\n",
    "\n",
    "      #ratingCount\n",
    "      try:\n",
    "        rat =  soup.find('meta',{'itemprop':\"ratingCount\"}).get('content')\n",
    "        # rat = soup.find('a', href=\"#other_reviews\" ).contents[2].split()\n",
    "        ratingCount.append(rat)  \n",
    "      except:\n",
    "        ratingCount.append(np.nan) \n",
    "\n",
    "      #reviewCount\n",
    "      try:\n",
    "        rew = soup.find('meta',{'itemprop':\"reviewCount\"}).get('content')\n",
    "        # rew = soup.find_all('a', href=\"#other_reviews\" )[1].contents[2].split()\n",
    "        reviewCount.append(rew)\n",
    "      except:\n",
    "        reviewCount.append(np.nan)\n",
    "\n",
    "\n",
    "      #NumberofPages\n",
    "      try:\n",
    "        pages = soup.find('span',{'itemprop':\"numberOfPages\"}).text\n",
    "        # pages= soup.find_all('span', itemprop=\"numberOfPages\")[0].contents[0]\n",
    "        NumberofPages.append(pages)\n",
    "      except:\n",
    "        NumberofPages.append(np.nan)\n",
    "\n",
    "      #PublishingDate\n",
    "      try:\n",
    "        date = soup.find_all('div',{'class':\"row\"})[1].text.strip()\n",
    "        # date = soup.find_all('div', class_=\"row\")[1].contents[0]\n",
    "        PublishingDate.append(date)\n",
    "      except:\n",
    "        PublishingDate.append(np.nan)\n",
    "\n",
    "      #Characters\n",
    "      chrs = []\n",
    "      try:\n",
    "        for el in soup.select('a[href*=characters]'):\n",
    "            chrs.append(el.string)\n",
    "        Characters.append(chrs)\n",
    "      except:\n",
    "        Characters.append(np.nan)\n",
    "\n",
    "      #Setting\n",
    "      stg = []\n",
    "      try:\n",
    "        for el in soup.select('a[href*=places]'):\n",
    "            stg.append(el.string)\n",
    "        Setting.append(stg)\n",
    "      except:\n",
    "        Setting.append(np.nan)\n",
    "      \n",
    "      url_ = 'https://www.goodreads.com//book/show/' + \"_\".join(file.split('_')[:-2])\n",
    "      url.append(url_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWSJOk60WZkW"
   },
   "outputs": [],
   "source": [
    "df.bookTitle = bookTitle  \n",
    "df.bookSeries = bookSeries\n",
    "df.bookAuthors = bookAuthors\n",
    "df.ratingValue = ratingValue\n",
    "df.Plot = Plot\n",
    "df.ratingCount = ratingCount\n",
    "df.reviewCount = reviewCount\n",
    "df.NumberofPages = NumberofPages\n",
    "df.PublishingDate = PublishingDate\n",
    "df.Characters = Characters\n",
    "df.Setting = Setting \n",
    "df.url =url\n",
    "df.to_csv(r'/content/drive/MyDrive/La_sapienza/ADM/data_final_3_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIuR3zrQlHCh"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'/content/drive/MyDrive/La_sapienza/ADM/data_final_0_2000.csv')\n",
    "df2 = pd.read_csv(r'/content/drive/MyDrive/La_sapienza/ADM/data_final_1_2000.csv')\n",
    "df3 = pd.read_csv(r'/content/drive/MyDrive/La_sapienza/ADM/data_final_2_2000.csv')\n",
    "df4 = pd.read_csv(r'/content/drive/MyDrive/La_sapienza/ADM/data_final_3_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xie0DbwO8v5N"
   },
   "outputs": [],
   "source": [
    "frame = [df1,df2,df3,df4]\n",
    "result = pd.concat(frame, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_NDevO58wBh"
   },
   "outputs": [],
   "source": [
    "result.to_csv(r'/content/drive/MyDrive/La_sapienza/ADM/1st_10000_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "t2Zy3F8rE4pO"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "txbQpFvJDeiO"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'/content/drive/MyDrive/La_sapienza/ADM/1st_10000_books.csv')\n",
    "df2 = pd.read_csv(r'/content/drive/MyDrive/La_sapienza/ADM/2st_10000_books.csv')\n",
    "df3 = pd.read_csv(r'/content/drive/MyDrive/La_sapienza//ADM/3st_10000_books.csv')\n",
    "frames = [df1, df2, df3]\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkgAgEN9eetj",
    "outputId": "8962dd5d-b2bb-4912-d90c-8b6b69e34794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26452, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE9YFFBrDWvO"
   },
   "source": [
    "# **2. Search Engine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries for the search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KM4nduJ0DWvO",
    "outputId": "f1581716-5d97-4daa-aeae-2b5163d7581c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uzxgspQSmqFm"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1CEWfk10DWvQ"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GljEjyCBDWvQ"
   },
   "outputs": [],
   "source": [
    "remove_punctuation = string.punctuation + '..' + '...' + \"''\" + \"``\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the search engine we first tokenize the plot, then we adjust some token which contains symbols or lower case letters.\n",
    "After this we:\n",
    "- Remove the punctuations\n",
    "- do Stemming\n",
    "- Remove digits\n",
    "- Not consider the ripetitive token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d27Pak7XDWvQ"
   },
   "outputs": [],
   "source": [
    "def search_engine(plot):\n",
    "    plot = re.sub(r'[^\\w\\s]', '', plot) \n",
    "    plot_tokens = nltk.word_tokenize(plot) #Tokenization\n",
    "    plot_tokens_lower = []\n",
    "    for e in plot_tokens:\n",
    "        plot_tokens_lower.extend(re.split(\"—|-|'\",e.lower()))#Lowercase and split the words which contains -\n",
    "    plot2 = [w for w in plot_tokens_lower if not w.lower() in stop_words]#Removing Stopwords\n",
    "    plot3 = [w for w in plot2 if not w in remove_punctuation] #Removing Punctuation\n",
    "    plot4 = []\n",
    "    for e in plot3:\n",
    "        # e = e.replace('.','')\n",
    "        plot4.append(ps.stem(e)) #Stemming\n",
    "    plot5 = []\n",
    "    for e in plot4:\n",
    "        if e[0].isnumeric() == False:\n",
    "            if e not in plot5:\n",
    "                plot5.append(e)\n",
    "    \n",
    "\n",
    "    # for \n",
    "    # print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "      \n",
    "    \n",
    "    return plot5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQeyws52DWvQ"
   },
   "source": [
    "Adding the column Plot_Token to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhXNIzc4DWvQ",
    "outputId": "79d323e1-db69-4cc7-ae8e-d70e2fc597d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26452/26452 [01:44<00:00, 254.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas() \n",
    "df['Plot_Token'] = df['Plot'].progress_apply(lambda x: search_engine(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oN972XGCDWvQ"
   },
   "source": [
    "### 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our inverse index we first store in the *words*  list all the token we have met tokenizing the plot. <br>\n",
    "Then we sort by alphabetical order the list. <br>\n",
    "In vocabulary we create a key-value relationship such that we have as a key the token and as a value the index of that particular word (this relationship is one to one since we have eliminated in words all the duplication) <br>\n",
    "We store the vocabulary in a json file to not lose informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bcq9kZSkDWvQ",
    "outputId": "dcdeef3d-760a-4d48-a7a2-b7010b1ca4a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26452/26452 [07:04<00:00, 62.30it/s]\n"
     ]
    }
   ],
   "source": [
    "#storing all the possible word of our dictionary\n",
    "words = []\n",
    "for el in tqdm(df['Plot_Token']):\n",
    "    for w in el:\n",
    "        if w not in words:\n",
    "            words.append(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mByc-v7gDWvQ"
   },
   "outputs": [],
   "source": [
    "#sorting words in alphabetical order  \n",
    "words=sorted(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BavEyWyHDWvQ",
    "outputId": "67996741-1422-4cfc-9d41-51f050c026b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113861/113861 [00:00<00:00, 900923.15it/s]\n"
     ]
    }
   ],
   "source": [
    "vocabulary={}\n",
    "for i in tqdm(range(len(words))):\n",
    "    vocabulary.update({words[i]:i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PcwxHqHtDWvR"
   },
   "outputs": [],
   "source": [
    "#saving in a new variable this vocabulary\n",
    "voc = vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TyJob-0CDWvR",
    "outputId": "147b8739-44c8-4110-d51d-e38177541a9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113861/113861 [00:00<00:00, 387400.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#preparing the vocabulary and the list for the value \n",
    "vocabulary={}\n",
    "for i in tqdm(range(len(words))):\n",
    "    vocabulary.update({words[i] : [] }) #we are going to fill the list with the document id that contains that token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "h6EpLy4mkANc"
   },
   "outputs": [],
   "source": [
    "# the json file where the output must be stored  \n",
    "out_file = open(r'/content/drive/MyDrive/La_sapienza/ADM/vocabulary.json', \"w\")  \n",
    "    \n",
    "json.dump(vocabulary, out_file)  \n",
    "    \n",
    "out_file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CfJjhhbDky1A"
   },
   "outputs": [],
   "source": [
    "out_file = open(r'/content/drive/MyDrive/La_sapienza/ADM/voc.json', \"w\")  \n",
    "    \n",
    "json.dump(voc, out_file)  \n",
    "    \n",
    "out_file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PB81jaAbDWvR",
    "outputId": "9edf2fe7-12b7-44f4-c0b0-6ada4ecb61bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26452it [00:00, 28022.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#preparing the list of document that contain token_j for each j\n",
    "for idx,el in tqdm(enumerate(df['Plot_Token'])):\n",
    "    for token in el:\n",
    "        vocabulary[token].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9wVD_eCDWvR",
    "outputId": "4dc49c2d-a5f6-4673-dcda-f6efb22297d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26452it [00:01, 14956.55it/s]\n"
     ]
    }
   ],
   "source": [
    "#store the inverse_index vocabulary in a json file\n",
    "inverse_index = {}\n",
    "for idx,el in tqdm(enumerate(df['Plot_Token'])):\n",
    "    for token in el:\n",
    "        inverse_index.update({voc[token] : vocabulary[token]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OcDmNU9yDWvR"
   },
   "outputs": [],
   "source": [
    "# with open(\"r'/content/drive/MyDrive/La_sapienza/ADM/inverse_index.json\", \"w\", encoding = \"utf8\") as v:\n",
    "#     v.write(json.dumps(inverse_index)) #store the vocabulary in a json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Veiw_lrkDWvT"
   },
   "source": [
    "### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part we are going to retrieve all the document that contains all the words of the query, to do this we look for the intersection among all the documents that contains at least one token of the query. In this way the intersection s will contain only the documents that present _every_ token of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zCtgjhuXDWvT"
   },
   "outputs": [],
   "source": [
    "q = 'World War'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Z60I_S5ADWvT"
   },
   "outputs": [],
   "source": [
    "# to be consistent we apply the search engine functions on the text query \n",
    "new_query = search_engine(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAfqAKd_DWvT",
    "outputId": "b698a0f4-2bfe-411b-fde6-e0162ea51390"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 421.28it/s]\n"
     ]
    }
   ],
   "source": [
    "s = set(inverse_index[voc[new_query[0]]])#in order to do the intersection we don't want an empty set in the beginning\n",
    "                                            #so we fill s with the documents that contains the first token of q\n",
    "for w in tqdm(new_query):\n",
    "    s = s.intersection(set(inverse_index[voc[w]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "y5-a3-ObDWvT"
   },
   "outputs": [],
   "source": [
    "#selecting all the document from df that contains all the token of q\n",
    "out = df.iloc[list(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "zW14XFfODWvT",
    "outputId": "e2d2ff97-7ca0-4ff1-d14a-8a672389b370"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Winter of the Witch</td>\n",
       "      <td>Following their adventures in The Bear and th...</td>\n",
       "      <td>https://www.goodreads.com//book/show/36621586-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Polgara the Sorceress</td>\n",
       "      <td>She soars above a world of warriors, kings, a...</td>\n",
       "      <td>https://www.goodreads.com//book/show/18884.Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>THE DIARY OF A CANADIAN NOBODY: The diary of a...</td>\n",
       "      <td>It's September 2001 and Arthur Lakelady is a...</td>\n",
       "      <td>https://www.goodreads.com//book/show/34610437-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Six Frigates: The Epic History of the Founding...</td>\n",
       "      <td>How \"a handful of bastards and outlaws fighti...</td>\n",
       "      <td>https://www.goodreads.com//book/show/39000.Six...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Executive Power</td>\n",
       "      <td>CIA superagent Mitch Rapp battles global terr...</td>\n",
       "      <td>https://www.goodreads.com//book/show/777211.Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26365</th>\n",
       "      <td>The Story of San Michele</td>\n",
       "      <td>The Story of San Michele (a villa built on th...</td>\n",
       "      <td>https://www.goodreads.com//book/show/288518.Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26375</th>\n",
       "      <td>Daybreak: Flatline</td>\n",
       "      <td>\"She's supposed to be just a job... a useless...</td>\n",
       "      <td>https://www.goodreads.com//book/show/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26381</th>\n",
       "      <td>A Dream of Red Mansions</td>\n",
       "      <td>\"A Dream of Red Mansions\" (Hung Lou Meng, som...</td>\n",
       "      <td>https://www.goodreads.com//book/show/158796.A_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26391</th>\n",
       "      <td>The New Tsar: The Rise and Reign of Vladimir P...</td>\n",
       "      <td>“A riveting, immensely detailed biography of ...</td>\n",
       "      <td>https://www.goodreads.com//book/show/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26399</th>\n",
       "      <td>Commissioning</td>\n",
       "      <td>They’re not saints, nor are they heroes. No, ...</td>\n",
       "      <td>https://www.goodreads.com//book/show/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1388 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               bookTitle  ...                                                url\n",
       "3                                The Winter of the Witch  ...  https://www.goodreads.com//book/show/36621586-...\n",
       "17                                 Polgara the Sorceress  ...  https://www.goodreads.com//book/show/18884.Pol...\n",
       "47     THE DIARY OF A CANADIAN NOBODY: The diary of a...  ...  https://www.goodreads.com//book/show/34610437-...\n",
       "57     Six Frigates: The Epic History of the Founding...  ...  https://www.goodreads.com//book/show/39000.Six...\n",
       "98                                       Executive Power  ...  https://www.goodreads.com//book/show/777211.Ex...\n",
       "...                                                  ...  ...                                                ...\n",
       "26365                           The Story of San Michele  ...  https://www.goodreads.com//book/show/288518.Th...\n",
       "26375                                 Daybreak: Flatline  ...              https://www.goodreads.com//book/show/\n",
       "26381                            A Dream of Red Mansions  ...  https://www.goodreads.com//book/show/158796.A_...\n",
       "26391  The New Tsar: The Rise and Reign of Vladimir P...  ...              https://www.goodreads.com//book/show/\n",
       "26399                                      Commissioning  ...              https://www.goodreads.com//book/show/\n",
       "\n",
       "[1388 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the output is sorted by document_id\n",
    "out.sort_index()[['bookTitle','Plot','url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NU18-ilQDWvT"
   },
   "source": [
    "# Second Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this second search engine we are going to change a little bit the previous search engine since the tfidf score takes care of ripetition of words, for this we are not going to remove the token that repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8-Sf1KvGDWvT"
   },
   "outputs": [],
   "source": [
    "#now we have ripetitive token for each plot\n",
    "def search_engine_rip(plot):\n",
    "    plot = re.sub(r'[^\\w\\s]', '', plot) \n",
    "    plot_tokens = nltk.word_tokenize(plot) #Tokenization\n",
    "    plot_tokens_lower = []\n",
    "    for e in plot_tokens:\n",
    "        plot_tokens_lower.extend(re.split('—|-',e.lower()))#Lowercase and split the words which contains -\n",
    "    plot2 = [w for w in plot_tokens_lower if not w.lower() in stop_words]#Removing Stopwords\n",
    "    plot3 = [w for w in plot2 if not w in remove_punctuation] #Removing Punctuation\n",
    "    plot4 = []\n",
    "    for e in plot3:\n",
    "        if e[0].isnumeric() == False:\n",
    "            plot4.append(ps.stem(e)) #Stemming\n",
    "    return plot4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWmKKf2TGC8J",
    "outputId": "66764950-eee7-476e-d465-9d0232fb2c3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26452/26452 [01:43<00:00, 255.22it/s]\n"
     ]
    }
   ],
   "source": [
    "df['Plot_Token'] = df['Plot'].progress_apply(lambda x: search_engine_rip(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-FLMNuRDWvT",
    "outputId": "89c0c7cc-0e62-4eaf-e045-efb5634f5634"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26452/26452 [00:00<00:00, 42931.21it/s]\n"
     ]
    }
   ],
   "source": [
    "#counting the ripetition of each token for each plot\n",
    "from collections import Counter\n",
    "df[\"Plot_Token_rip\"] = df[\"Plot_Token\"].progress_apply(lambda x : Counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FIvAgWmHDWvT",
    "outputId": "52697123-636f-4737-e4b7-614babdc692e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>Plot</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>NumberofPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>url</th>\n",
       "      <th>Plot_Token</th>\n",
       "      <th>Plot_Token_rip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Elf Queen of Shannara</td>\n",
       "      <td>(Heritage of Shannara #3)</td>\n",
       "      <td>Terry Brooks</td>\n",
       "      <td>4 . 0 4</td>\n",
       "      <td>\"Find the Elves and return them to the world ...</td>\n",
       "      <td>29558</td>\n",
       "      <td>323</td>\n",
       "      <td>416 pages</td>\n",
       "      <td>Published\\n        March 4th 1998\\n         by...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.goodreads.com//book/show/15566.The...</td>\n",
       "      <td>[find, elv, return, world, men, shade, druid, ...</td>\n",
       "      <td>{'find': 3, 'elv': 6, 'return': 3, 'world': 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Her Body and Other Parties</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carmen Maria Machado</td>\n",
       "      <td>3 . 9 1</td>\n",
       "      <td>In Her Body and Other Parties, Carmen Maria M...</td>\n",
       "      <td>38646</td>\n",
       "      <td>5590</td>\n",
       "      <td>248 pages</td>\n",
       "      <td>Published\\n        October 3rd 2017\\n         ...</td>\n",
       "      <td>['characters-of-color']</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.goodreads.com//book/show/33375622-...</td>\n",
       "      <td>[bodi, parti, carmen, maria, machado, blith, d...</td>\n",
       "      <td>{'bodi': 3, 'parti': 3, 'carmen': 2, 'maria': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Self Growth - 2: Self Growth Through Self Este...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ron Millicent, Millie Parker</td>\n",
       "      <td>4 . 3 7</td>\n",
       "      <td>This book is an amazing story of reacting to ...</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>58 pages</td>\n",
       "      <td>Published\\n        March 10th 2017\\n         b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.goodreads.com//book/show/34593095-...</td>\n",
       "      <td>[book, amaz, stori, react, situat, recogn, gif...</td>\n",
       "      <td>{'book': 5, 'amaz': 2, 'stori': 5, 'react': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The Winter of the Witch</td>\n",
       "      <td>(Winternight Trilogy #3)</td>\n",
       "      <td>Katherine Arden</td>\n",
       "      <td>4 . 5 0</td>\n",
       "      <td>Following their adventures in The Bear and th...</td>\n",
       "      <td>40211</td>\n",
       "      <td>5793</td>\n",
       "      <td>384 pages</td>\n",
       "      <td>Published\\n        January 8th 2019\\n         ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.goodreads.com//book/show/36621586-...</td>\n",
       "      <td>[follow, adventur, bear, nightingal, girl, tow...</td>\n",
       "      <td>{'follow': 2, 'adventur': 2, 'bear': 2, 'night...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Undetected</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeffrey Marshall</td>\n",
       "      <td>4 . 3 6</td>\n",
       "      <td>UNDETECTED Suzy Perry, a lovely, accomplished...</td>\n",
       "      <td>610</td>\n",
       "      <td>24</td>\n",
       "      <td>232 pages</td>\n",
       "      <td>Published\\n        August 6th 2019\\n         b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.goodreads.com//book/show/52123874-...</td>\n",
       "      <td>[undetect, suzi, perri, love, accomplish, olde...</td>\n",
       "      <td>{'undetect': 2, 'suzi': 5, 'perri': 4, 'love':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My Hero Academia, Vol. 1</td>\n",
       "      <td>(My Hero Academia #1)</td>\n",
       "      <td>Kohei Horikoshi</td>\n",
       "      <td>4 . 5 0</td>\n",
       "      <td>What would the world be like if 80 percent of...</td>\n",
       "      <td>49154</td>\n",
       "      <td>1455</td>\n",
       "      <td>192 pages</td>\n",
       "      <td>Published\\n        August 4th 2015\\n         b...</td>\n",
       "      <td>['MHA NEXT GENERATI...:', 'NEXT GENERATION CHA...</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.goodreads.com//book/show/25074597-...</td>\n",
       "      <td>[would, world, like, percent, popul, manifest,...</td>\n",
       "      <td>{'would': 10, 'world': 2, 'like': 3, 'percent'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Wolfsong</td>\n",
       "      <td>(Green Creek #1)</td>\n",
       "      <td>T.J. Klune</td>\n",
       "      <td>4 . 3 8</td>\n",
       "      <td>This edition is out of print. For the current...</td>\n",
       "      <td>19000</td>\n",
       "      <td>3816</td>\n",
       "      <td>400 pages</td>\n",
       "      <td>Published\\n        June 20th 2016\\n         by...</td>\n",
       "      <td>['second-characters-rock']</td>\n",
       "      <td>['Oregon']</td>\n",
       "      <td>https://www.goodreads.com//book/show/29233804-...</td>\n",
       "      <td>[edit, print, current, kindl, edit, see, hereo...</td>\n",
       "      <td>{'edit': 4, 'print': 2, 'current': 2, 'kindl':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The Mistress of Spices</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chitra Banerjee Divakaruni</td>\n",
       "      <td>3 . 4 8</td>\n",
       "      <td>Magical, tantalizing, and sensual, The Mistre...</td>\n",
       "      <td>12646</td>\n",
       "      <td>1008</td>\n",
       "      <td>338 pages</td>\n",
       "      <td>Published\\n        February 17th 1998\\n       ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Oakland, California']</td>\n",
       "      <td>https://www.goodreads.com//book/show/94669.The...</td>\n",
       "      <td>[magic, tantal, sensual, mistress, spice, stor...</td>\n",
       "      <td>{'magic': 3, 'tantal': 2, 'sensual': 2, 'mistr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Mistress of Mellyn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Victoria Holt</td>\n",
       "      <td>3 . 9 0</td>\n",
       "      <td>Mount Mellyn stood as proud and magnificent a...</td>\n",
       "      <td>8167</td>\n",
       "      <td>545</td>\n",
       "      <td>240 pages</td>\n",
       "      <td>Published\\n        1960\\n         by Readers D...</td>\n",
       "      <td>['Gilly', 'Martha Leigh', 'Connan TreMellyn', ...</td>\n",
       "      <td>['Cornwall, England']</td>\n",
       "      <td>https://www.goodreads.com//book/show/211953.Mi...</td>\n",
       "      <td>[mount, mellyn, stood, proud, magnific, envis,...</td>\n",
       "      <td>{'mount': 2, 'mellyn': 2, 'stood': 2, 'proud':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The Conformist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alberto Moravia, Tami Calliope</td>\n",
       "      <td>3 . 9 8</td>\n",
       "      <td>Secrecy and Silence are second nature to Marc...</td>\n",
       "      <td>1968</td>\n",
       "      <td>141</td>\n",
       "      <td>323 pages</td>\n",
       "      <td>Published\\n        November 1st 1999\\n        ...</td>\n",
       "      <td>['Marcello', 'Giulia', 'Quadri,', 'Lina']</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.goodreads.com//book/show/67146.The...</td>\n",
       "      <td>[secreci, silenc, second, natur, marcello, cle...</td>\n",
       "      <td>{'secreci': 2, 'silenc': 2, 'second': 2, 'natu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                     Plot_Token_rip\n",
       "0           0  ...  {'find': 3, 'elv': 6, 'return': 3, 'world': 2,...\n",
       "1           1  ...  {'bodi': 3, 'parti': 3, 'carmen': 2, 'maria': ...\n",
       "2           2  ...  {'book': 5, 'amaz': 2, 'stori': 5, 'react': 3,...\n",
       "3           3  ...  {'follow': 2, 'adventur': 2, 'bear': 2, 'night...\n",
       "4           4  ...  {'undetect': 2, 'suzi': 5, 'perri': 4, 'love':...\n",
       "5           5  ...  {'would': 10, 'world': 2, 'like': 3, 'percent'...\n",
       "6           6  ...  {'edit': 4, 'print': 2, 'current': 2, 'kindl':...\n",
       "7           7  ...  {'magic': 3, 'tantal': 2, 'sensual': 2, 'mistr...\n",
       "8           8  ...  {'mount': 2, 'mellyn': 2, 'stood': 2, 'proud':...\n",
       "9           9  ...  {'secreci': 2, 'silenc': 2, 'second': 2, 'natu...\n",
       "\n",
       "[10 rows x 16 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KbMp8k-DWvT"
   },
   "source": [
    " ## $tf_idf_i^j$ where $tf_i=$# ripetition/# totaltoken and $df_j^i=log$(# docs/# docswithtoken_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHC3oaJrDWvU"
   },
   "source": [
    "Calculate tf for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "mIo74VujDWvY"
   },
   "outputs": [],
   "source": [
    "def tf_i(plot_rip):\n",
    "    tot_token = 0\n",
    "    for k, v in plot_rip.items():\n",
    "        tot_token += v #numbers of total tokens in the plot\n",
    "    tf = {}\n",
    "    for token, rip in plot_rip.items():#the values in this dictionary are the ripetition of that specific token\n",
    "        tf[token] = rip / tot_token\n",
    "    return tf        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRhV9S3YDWvY",
    "outputId": "28d9bf78-541e-42be-df46-0e4f285a3197"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26452/26452 [00:00<00:00, 37546.77it/s]\n"
     ]
    }
   ],
   "source": [
    "tf = []\n",
    "for i in tqdm(range(len(df[\"Plot_Token_rip\"]))):\n",
    "    tf.append(tf_i(df[\"Plot_Token_rip\"][i])) #applying the previous function to each plot\n",
    "df[\"tf\"] = tf #adding the column tf to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "W0No7w2XDWvY",
    "outputId": "916c9848-ea85-4fe1-dd01-7cba6c159163",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>Plot</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>NumberofPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>url</th>\n",
       "      <th>Plot_Token</th>\n",
       "      <th>Plot_Token_rip</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Elf Queen of Shannara</td>\n",
       "      <td>(Heritage of Shannara #3)</td>\n",
       "      <td>Terry Brooks</td>\n",
       "      <td>4 . 0 4</td>\n",
       "      <td>\"Find the Elves and return them to the world ...</td>\n",
       "      <td>29558</td>\n",
       "      <td>323</td>\n",
       "      <td>416 pages</td>\n",
       "      <td>Published\\n        March 4th 1998\\n         by...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.goodreads.com//book/show/15566.The...</td>\n",
       "      <td>[find, elv, return, world, men, shade, druid, ...</td>\n",
       "      <td>{'find': 3, 'elv': 6, 'return': 3, 'world': 2,...</td>\n",
       "      <td>{'find': 0.0196078431372549, 'elv': 0.03921568...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                                 tf\n",
       "0           0  ...  {'find': 0.0196078431372549, 'elv': 0.03921568...\n",
       "\n",
       "[1 rows x 17 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GaCpH2NDWvY"
   },
   "source": [
    "Creating Idf for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "IeWdz81HDWvY"
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CU38HNwZDWvY",
    "outputId": "dfc89a65-5185-4e43-fbbd-fa8a8360bdcf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26452/26452 [00:04<00:00, 5448.82it/s]\n"
     ]
    }
   ],
   "source": [
    "idf = {}\n",
    "for el in tqdm(df['Plot_Token']):   \n",
    "    for token in el:\n",
    "         idf.update({ token : math.log(len(df)/ len(vocabulary[token]))})   #applying the formula for each token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Av3TMgW3Ko-_"
   },
   "outputs": [],
   "source": [
    "# ' '.join(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-n8dMnuDWvY"
   },
   "source": [
    "### Create the new inverse index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tYQkYgT3DWvY"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "inverse_index_tfidf = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "R_VF0wqZob_u"
   },
   "outputs": [],
   "source": [
    "invert = inverse_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "opqPZWpq1t-g"
   },
   "outputs": [],
   "source": [
    "new_voc = dict([(value, key) for key, value in voc.items()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ey6UZbIYq8zb",
    "outputId": "03867d7d-75d9-43c7-a63e-9ec88e374e0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113861/113861 [00:03<00:00, 36835.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(invert.keys()):\n",
    "  l = []\n",
    "  token = new_voc[key]\n",
    "  for i in invert[key]:  \n",
    "    l.append((i, tf[i][token]*idf[token]))\n",
    "  invert[key] = l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2) Execute the query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "DUkWMGgmDWvZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "KSRmTw9SDWvZ"
   },
   "outputs": [],
   "source": [
    "arr_q = np.zeros(len(vocabulary))\n",
    "for w in new_query:\n",
    "    arr_q[voc[w]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2jvGfiqDWvZ"
   },
   "source": [
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gz1CYphkDWvZ",
    "outputId": "e1920300-f5a3-4b85-faf9-fac19ed07419"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.norm(arr_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uj6DT6EBDWvZ",
    "outputId": "3b787b7f-9d96-4b7f-9e22-1a77b9954fe5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1388/1388 [00:00<00:00, 2936.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate the similarity only for the documents in s (intersection)\n",
    "cosine_similarity = {}\n",
    "for doc in tqdm(s):\n",
    "    norm_q = np.linalg.norm(arr_q)\n",
    "    norm_doc = 0\n",
    "    for v in df.tf[doc].values():\n",
    "        norm_doc += v*v\n",
    "    den = norm_q*np.sqrt(norm_doc)\n",
    "    num = 0\n",
    "    for i in list(np.where(arr_q==1))[0]:\n",
    "        # num += df.tf[doc][list(voc.keys())[list(voc.values()).index(i)]]\n",
    "        num += df.tf[doc][new_voc[i]]\n",
    "    cos_sim = num/den\n",
    "    cosine_similarity.update({doc : cos_sim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "NN18dkiaDWvZ"
   },
   "outputs": [],
   "source": [
    "df_cos = df.iloc[list(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VekbrufKDWvZ",
    "outputId": "013176b7-0c22-45c7-a7d7-9a146bc5adf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_cos[\"Cos_Similarity\"] = list(cosine_similarity.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "JsEaOVEYKn39"
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "heap_sort = list(cosine_similarity.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "kdBPtDKAMn-M"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "cos_out = pd.DataFrame()\n",
    "for cos_similarity_ in  heapq.nlargest(k, heap_sort) :\n",
    "  cos_out = cos_out.append(df_cos[df_cos['Cos_Similarity'] == cos_similarity_][['bookTitle','Plot','url', 'Cos_Similarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "-BeU-yLRJUJW",
    "outputId": "f257bb84-ddb2-4717-f661-0cc4fccef5f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>url</th>\n",
       "      <th>Cos_Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>Hetalia: Axis Powers, Vol. 1</td>\n",
       "      <td>In these hilarious comic strips, the world's ...</td>\n",
       "      <td>https://www.goodreads.com//book/show/7942008-h...</td>\n",
       "      <td>0.655610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>The Wars</td>\n",
       "      <td>Robert Ross, a sensitive nineteen-year-old Ca...</td>\n",
       "      <td>https://www.goodreads.com//book/show/29898.The...</td>\n",
       "      <td>0.609272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19681</th>\n",
       "      <td>World War II Chronicle</td>\n",
       "      <td>The World War II Chronicle provides a full sw...</td>\n",
       "      <td>https://www.goodreads.com//book/show/</td>\n",
       "      <td>0.606314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7442</th>\n",
       "      <td>The Winds of War</td>\n",
       "      <td>Like no other masterpiece of historical ficti...</td>\n",
       "      <td>https://www.goodreads.com//book/show/21484.The...</td>\n",
       "      <td>0.518545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Memoirs of the Second World War</td>\n",
       "      <td>The quintessential account of the Second Worl...</td>\n",
       "      <td>https://www.goodreads.com//book/show/25589.Mem...</td>\n",
       "      <td>0.517357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>The Beauty and the Sorrow: An Intimate History...</td>\n",
       "      <td>Four devastating years told by twenty eyewitn...</td>\n",
       "      <td>https://www.goodreads.com//book/show/10900053-...</td>\n",
       "      <td>0.513870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>The Second World War</td>\n",
       "      <td>The definitive, Nobel Prize–winning history o...</td>\n",
       "      <td>https://www.goodreads.com//book/show/25587.The...</td>\n",
       "      <td>0.510662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23422</th>\n",
       "      <td>Tapestry</td>\n",
       "      <td>As the vivid events of World War II plunge th...</td>\n",
       "      <td>https://www.goodreads.com//book/show/</td>\n",
       "      <td>0.510310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12954</th>\n",
       "      <td>'Rommel?' 'Gunner Who?': A Confrontation in th...</td>\n",
       "      <td>This is the second volume of Mr Milligan's re...</td>\n",
       "      <td>https://www.goodreads.com//book/show/250949._R...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22434</th>\n",
       "      <td>Generals Die in Bed</td>\n",
       "      <td>As the world marks the 100th anniversary of t...</td>\n",
       "      <td>https://www.goodreads.com//book/show/452211.Ge...</td>\n",
       "      <td>0.496929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               bookTitle  ... Cos_Similarity\n",
       "9709                        Hetalia: Axis Powers, Vol. 1  ...       0.655610\n",
       "1677                                            The Wars  ...       0.609272\n",
       "19681                             World War II Chronicle  ...       0.606314\n",
       "7442                                    The Winds of War  ...       0.518545\n",
       "792                      Memoirs of the Second World War  ...       0.517357\n",
       "10863  The Beauty and the Sorrow: An Intimate History...  ...       0.513870\n",
       "13049                               The Second World War  ...       0.510662\n",
       "23422                                           Tapestry  ...       0.510310\n",
       "12954  'Rommel?' 'Gunner Who?': A Confrontation in th...  ...       0.500000\n",
       "22434                                Generals Die in Bed  ...       0.496929\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12dn254pDWva"
   },
   "source": [
    "# 3. Define a new score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn00E22ZDWva"
   },
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgIAwymjDWva"
   },
   "source": [
    "Let the user enter:\n",
    "  - Number of pages wished.\n",
    "  - Last year of publishing wished.\n",
    "  - The author.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zapzXOuoDWva"
   },
   "source": [
    "Then:\n",
    " - Filter by the author <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y9N52LqDWva"
   },
   "source": [
    "Similarity: <hr>\n",
    "    $similarity = Rating\\_count/Rating\\_value * 1/2^{|Page\\_inserted-Page\\_document|+|Year\\_inserted-Year\\_document|}$ <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the document sorted in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the meaning of our similarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to return the documents that are consistent with what the user asked but also considering how much the books are famous. <br>\n",
    "In order to consider the **reputation** of the book we use the rating value and the rating count, we take this decision to not give priority to books that have a high number of rating stars in case a little number of people provided them. <br>\n",
    "At this point we should think to a method that takes care of the **requests** of the user; we decide to divide by 2 elevated at the power of $|Page\\_inserted-Page\\_document|+|Year\\_inserted-Year\\_document|$; this way we have higher value when the number of pages is far from the requests, same for the year. The final comment is on the decision of taking the power of this value : the first osservation should be taken by avoiding the problem of having zero in the differences, the second one is because we have the risk to give too much importance to the reputation (the numerator usually is very big) and less to the requests (the value of $|Page\\_inserted-Page\\_document|+|Year\\_inserted-Year\\_document|$ isn't that big)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Tokenize the bookAuthor and the query about the author\n",
    "We do this step just to lighten the computation of our similarity but this step isn't necessary. We use the first search engine since there is no point in considering ripetition in the author column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHBocr6TR_A9",
    "outputId": "88727bad-5574-4588-e6ef-ac417c4ca425"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26452/26452 [00:04<00:00, 5739.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['Authors_Token'] = df['bookAuthors'].progress_apply(lambda x: search_engine(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "DgmudMP8R_G7"
   },
   "outputs": [],
   "source": [
    "# We let the user enter the first name or the last name or both\n",
    "q_1 = 'John'\n",
    "#we do search engine on the query just to be consistent\n",
    "new_q_1 = search_engine(q_1)\n",
    "# We let the user enter the number of pages wished\n",
    "q_2 = 100\n",
    "# We let the user enter the year of publish wished\n",
    "q_3 = 1999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Filter by the author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve pages and year just for the document filtered by the author (saving computation time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Rgqf-eLrR_Yo"
   },
   "outputs": [],
   "source": [
    "#just repeating the steps used for the plot but for the bookAuthors\n",
    "\n",
    "authors = []\n",
    "for el in df['Authors_Token']:\n",
    "    for a in el:\n",
    "        if a not in authors:\n",
    "            authors.append(a) \n",
    "      \n",
    "    \n",
    "authors=sorted(authors)\n",
    "\n",
    "\n",
    "vocabulary_authors={}\n",
    "for i in range(len(authors)):\n",
    "    vocabulary_authors.update({authors[i]:i})\n",
    "voc_authors = vocabulary_authors\n",
    "            \n",
    "vocabulary_authors={}\n",
    "for i in range(len(authors)):\n",
    "    vocabulary_authors.update({authors[i] : [] })\n",
    "# with open(\"vocabulary.json\", \"w\", encoding = \"utf8\") as v:\n",
    "#     v.write(json.dumps(vocabulary_authors)) #store the vocabulary in a json file\n",
    "    \n",
    "    \n",
    "for idx,el in enumerate(df['Authors_Token']):\n",
    "    for token in el:\n",
    "        vocabulary_authors[token].append(idx)\n",
    "        \n",
    "        \n",
    "inverse_index_authors = {}       \n",
    "for idx,el in enumerate(df['Authors_Token']):\n",
    "    for token in el:\n",
    "        inverse_index_authors.update({voc_authors[token] : vocabulary_authors[token]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "hksjgGK6R_dE"
   },
   "outputs": [],
   "source": [
    "#We use intersection to do the filtration\n",
    "s = set(inverse_index_authors[voc_authors[new_q_1[0]]])\n",
    "for a in new_q_1:\n",
    "    s = s.intersection(set(inverse_index_authors[voc_authors[a]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4dOhnkRcR_jQ"
   },
   "outputs": [],
   "source": [
    "out = df.iloc[list(s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)  Retrieve the number of pages in the column NumberOfPages and year in the column PublishingDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "QfVk-7fZR_pD"
   },
   "outputs": [],
   "source": [
    "# Need to use this code instead of just split to take year\n",
    "\n",
    "def return_publishing_date(date_string):\n",
    "\n",
    "    for j in re.findall('\\d+', date_string):#using regex to catch the year of the last publication\n",
    "        if len(j) == 4:\n",
    "            return j\n",
    "            break\n",
    "\n",
    "df['PublishingDate']=df['PublishingDate'].apply(lambda x: return_publishing_date(str(x)) )\n",
    "# df['Pages']=df['NumberofPages'].apply(lambda x: str(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "1NvxS_ZDSMlw"
   },
   "outputs": [],
   "source": [
    "#adding column of pages and years to the dataframe of books filtered by the author\n",
    "df['Year'] = df['PublishingDate']\n",
    "df['Pages']=df['NumberofPages'].apply(lambda x: str(x).split()[0] if pd.isna(x) == False else '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Implementing our Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "0uQZMXsASMuu"
   },
   "outputs": [],
   "source": [
    "new_similarity={}\n",
    "for i in range(len(out)): #for each element of out\n",
    "    star= float(df['ratingValue'][i].replace(\" \", ''))\n",
    "#     star = df['ratingValue'][i].split()  #taking the int number of ratingValue\n",
    "    num= float(df['ratingCount'][i])/star #numerator\n",
    "    if df['Pages'][i].isdigit() and df['Year'][i].isdigit(): #avoidinf NaN value and string value\n",
    "        den = math.log(pow(2 , (abs(q_2-int(df['Pages'][i]))+abs(q_3-int(df['Year'][i]))))) #denominator\n",
    "        sim = num/den #calculating the similarity only if we have number of pages and the year\n",
    "    else:\n",
    "        sim=0 #if haven't number of pages or the year similarity is zero\n",
    "    new_similarity.update({i:sim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrjkbSYPSM1G",
    "outputId": "a5b50a0b-36c1-41b2-c5e4-0210fcc47c4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_sim = df.iloc[list(s)]\n",
    "df_sim[\"New_Similarity\"] = list(new_similarity.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "eGFBApgeZWOi"
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "heap_sort = list(new_similarity.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "tAJhnzboZge7"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "new_out = pd.DataFrame()\n",
    "for cos_similarity_ in  heapq.nlargest(k, heap_sort) :\n",
    "  new_out = new_out.append(df_sim[df_sim['New_Similarity'] == cos_similarity_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "P9zPuxsnZg4y",
    "outputId": "bbdc0ef9-4ad0-4927-a17e-e737d6aaffce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>url</th>\n",
       "      <th>New_Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>Julie of the Wolves</td>\n",
       "      <td>Alone and lost—on the North Slope of AlaskaMi...</td>\n",
       "      <td>https://www.goodreads.com//book/show/386286.Ju...</td>\n",
       "      <td>1516.510805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>The Second World War</td>\n",
       "      <td>The definitive, Nobel Prize–winning history o...</td>\n",
       "      <td>https://www.goodreads.com//book/show/25587.The...</td>\n",
       "      <td>626.513567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21218</th>\n",
       "      <td>Taken</td>\n",
       "      <td>Dark clouds gatherA storm is breaking...With ...</td>\n",
       "      <td>https://www.goodreads.com//book/show/</td>\n",
       "      <td>468.132587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24038</th>\n",
       "      <td>Tik-Tok</td>\n",
       "      <td>Something has gone very seriously wrong with ...</td>\n",
       "      <td>https://www.goodreads.com//book/show/</td>\n",
       "      <td>368.567804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Giles Goat-Boy</td>\n",
       "      <td>In this outrageously farcical adventure, hero...</td>\n",
       "      <td>https://www.goodreads.com//book/show/144629.Gi...</td>\n",
       "      <td>363.447979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16102</th>\n",
       "      <td>Florence &amp; Giles</td>\n",
       "      <td>A gripping, sinister Gothic tale inspired by ...</td>\n",
       "      <td>https://www.goodreads.com//book/show/7343071-f...</td>\n",
       "      <td>343.694674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17696</th>\n",
       "      <td>John Le Carré: Three Complete Novels [Tinker, ...</td>\n",
       "      <td>Three complete, previously-issued novels, eac...</td>\n",
       "      <td>https://www.goodreads.com//book/show/367679.Jo...</td>\n",
       "      <td>320.244548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>Stand on Zanzibar</td>\n",
       "      <td>Norman Niblock House is a rising executive at...</td>\n",
       "      <td>https://www.goodreads.com//book/show/41069.Sta...</td>\n",
       "      <td>300.464373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8331</th>\n",
       "      <td>A Widow for One Year</td>\n",
       "      <td>“One night when she was four and sleeping in ...</td>\n",
       "      <td>https://www.goodreads.com//book/show/4659.A_Wi...</td>\n",
       "      <td>298.637694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11859</th>\n",
       "      <td>The Oxford English Dictionary  (20 Volume Set)</td>\n",
       "      <td>The Oxford English Dictionary has long been c...</td>\n",
       "      <td>https://www.goodreads.com//book/show/644538.Th...</td>\n",
       "      <td>291.359920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               bookTitle  ... New_Similarity\n",
       "3352                                 Julie of the Wolves  ...    1516.510805\n",
       "13049                               The Second World War  ...     626.513567\n",
       "21218                                              Taken  ...     468.132587\n",
       "24038                                            Tik-Tok  ...     368.567804\n",
       "931                                       Giles Goat-Boy  ...     363.447979\n",
       "16102                                   Florence & Giles  ...     343.694674\n",
       "17696  John Le Carré: Three Complete Novels [Tinker, ...  ...     320.244548\n",
       "3396                                   Stand on Zanzibar  ...     300.464373\n",
       "8331                                A Widow for One Year  ...     298.637694\n",
       "11859     The Oxford English Dictionary  (20 Volume Set)  ...     291.359920\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_out[['bookTitle','Plot','url', 'New_Similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2Q7CRAZR_vL"
   },
   "outputs": [],
   "source": [
    "# out = df_sim.sort_values(by=['New_Similarity'],ascending=False)\n",
    "# # out[['bookTitle','Plot','url', 'New_Similarity' ,'bookAuthors','ratingValue','ratingCount','Pages','Year' ]].head()\n",
    "# out[['bookTitle', 'New_Similarity' ,'bookAuthors','ratingValue','ratingCount','Pages','Year' ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aW0XjGnGr8l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c2IcShEGsON"
   },
   "source": [
    "# **4. Make a nice visualization!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step we consider the bookSeries and we create two new columns: one that contain the title of the series and another that contain the number of the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JmL8-KpUbwAi"
   },
   "outputs": [],
   "source": [
    "df['bookseries_name'] = df['bookSeries'].apply(lambda x : x.replace('(','').replace(')', '').split('#')[0].strip() if pd.isna(x) == False else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrieve the year of the first publication and the number of pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "qPFE6hgmbW65"
   },
   "outputs": [],
   "source": [
    "def get_series_number(x):\n",
    "  if pd.isna(x) == False:\n",
    "    try:\n",
    "      return eval(x.replace('(','').replace(')', '').split('#')[-1])\n",
    "    except:\n",
    "      return ''\n",
    "  else:\n",
    "    return ''\n",
    "df['bookseries_number'] = df['bookSeries'].apply(lambda x :  get_series_number(x) )\n",
    "df['Pages']=df['NumberofPages'].apply(lambda x: eval(str(x).split()[0]) if pd.isna(x) == False else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the code for a specific series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "RJtDKpXHm1hN",
    "outputId": "48e2a54d-da54-4158-edbc-92afe8b59624"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#considering only the rows containig the series of interest\n",
    "new_df = df[df['bookseries_name'] == 'Winternight Trilogy']\n",
    "new_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#sorting the dataset by the year\n",
    "new_df.sort_values(['Year'], inplace =True)\n",
    "\n",
    "x = new_df['bookSeries'].values #the x axis contains the years of publication\n",
    "y = new_df['Pages'].values.cumsum() #the y axis contains the cumulative sum of the pages\n",
    "\n",
    "sns.barplot(x=x,y=y)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Algorithmic Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bMzRANAxAIWw"
   },
   "outputs": [],
   "source": [
    "#Given a string s as an input, this function returns the list of all subsequences in alphabetical order. \n",
    "#Then with max(l, key = len) we will return the length of the longest subsequence in alphabetical order.\n",
    "def longest_sequence(s):\n",
    "    if len(s)==1:\n",
    "        return [s]\n",
    "    else:\n",
    "        l=longest_sequence(s[:len(s)-1])\n",
    "        for e in l:\n",
    "            if s[-1]>e[-1]:\n",
    "                l.append(e+s[-1])\n",
    "        l.append(s[-1])\n",
    "        return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1w755JjYAPk0",
    "outputId": "f4f8ba4e-6094-4a5f-d75a-8c2cfd7b066b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CDFILNOPSTY'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = longest_sequence('CADFECEILGJHABNOFPSTIRYOEABILCNR')\n",
    "max(l, key = len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s =  'azcbobobeghakl'\n",
    "l = longest_sequence(s)\n",
    "len(max(l,key = len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_2 = longest_sequence(\"CADFECEILGJHABNOFPSTIRYOEABILCNRCADFECEILGJHABNOFPSTIRYOEABILCNRCADFECEILGJHABNOFPSTIRYOEABILCNRCADFECEILGJHABNOFPSTIRYOEABILCNR\")\n",
    "len(max(l_2,key = len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX_erAMe9qZj"
   },
   "source": [
    "###  Let's use simulation to find if time Versus len(string) is **exponential**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujBo_LJeCIwl",
    "outputId": "369edbf0-c6c8-4dbd-d5c2-c40fa0b34060"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:23<00:00, 19.19s/it]\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "from tqdm import tqdm\n",
    "final_time_for_simulation = []\n",
    "for k in tqdm(range(60, 100, 2)):\n",
    "  time_of_simulation = []\n",
    "  LCS_value = []\n",
    "  for i in range(10):\n",
    "    s = \"\".join(random.choices(string.ascii_lowercase, k = k))\n",
    "    start = timeit.default_timer()\n",
    "    l = longest_sequence(s)\n",
    "    LCS_value.append(max(l, key = len))\n",
    "    stop = timeit.default_timer()\n",
    "    time_of_simulation.append(stop - start)  \n",
    "  final_time_for_simulation.append(np.mean(time_of_simulation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xx6i07qLCyti",
    "outputId": "dfeb1b18-a02f-4f97-8399-5b18ced6d36a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17652730000118028,\n",
       " 0.24686761000048135,\n",
       " 0.14807195000103093,\n",
       " 0.2341107699998247,\n",
       " 0.39353709999923014,\n",
       " 0.34881012999831,\n",
       " 0.6748477600012848,\n",
       " 0.6778793800003768,\n",
       " 0.48102108999955817,\n",
       " 0.7089887599991925,\n",
       " 1.6281101300002774,\n",
       " 1.720258389999799,\n",
       " 2.2240570800015123,\n",
       " 1.1697477999987314,\n",
       " 1.5658612200022617,\n",
       " 2.778010560001712,\n",
       " 2.958590919998824,\n",
       " 4.651481200000125,\n",
       " 5.477151409997896,\n",
       " 10.11106607000038]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_time_for_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "d9Px8nEcERTJ",
    "outputId": "756e82c7-2329-4e05-871b-b37e66685de3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b5af469d88>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLot that shows exponential time required\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(60, 100, 2),final_time_for_simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the worst case scenario when the new character is higher in alphabetic order than the latest character of every string in the list: <br>\n",
    "When n=1 the list is empty and adds 1 <br>\n",
    "When n=2 it checks 1 elements from the list and adds 1+1 <br>\n",
    "When n=3 it checks 3 elements from the list and adds 3+1 <br>\n",
    "When n=4 it checks 7 elements from the list and adds 7+1 <br>\n",
    "When n=5 it checks 15 elements from the list and adds 15+1 <br>\n",
    "So generally at every n >=2 it checks 2^(n-1)-1 elements (without even taking into account the recursive calls), therefore it's exponential <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the course we have seen how to use dynamic programming to find the longest common subsequence of two string. We can use the same reasoning consider as strings our input s and the alphabet string \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_dynamic(s, alph):  \n",
    "    n = len(s) \n",
    "    m = len(alph) \n",
    "    CS = [[None]*(m+1) for i in range(n+1)] \n",
    "    for i in range(n+1): \n",
    "        for j in range(m+1): \n",
    "            if i == 0 or j == 0 : \n",
    "                CS[i][j] = 0\n",
    "            elif s[i-1] == alph[j-1]: \n",
    "                CS[i][j] = CS[i-1][j-1]+1\n",
    "            else: \n",
    "                CS[i][j] = max(CS[i-1][j] , CS[i][j-1])\n",
    "    return CS[n][m] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s = 'AZCBOBOBEGHAKL'\n",
    "alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "lcs_dynamic(s,alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.06 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s = \"CADFECEILGJHABNOFPSTIRYOEABILCNRCADFECEILGJHABNOFPSTIRYOEABILCNRCADFECEILGJHABNOFPSTIRYOEABILCNRCADFECEILGJHABNOFPSTIRYOEABILCNR\"\n",
    "lcs_dynamic(s,alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Time\n",
    "Since we have two nested for loops with costant running time operations the running time is $\\theta(mn)$ where m and n are the lenghts of the strings considered.\n",
    "In our case m has always the same value (24) so we can see our running time as $\\theta(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (last) BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prove the formula by induction: <br>\n",
    "1) Base Case : i = 1.<br>\n",
    "&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   $X[1] = 1$ since there no exist such a j as requested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Induction Step: i→i+1. <br>\n",
    "&nbsp;  We can observe that if there exist such  a j,\n",
    "&nbsp; then $X[i+1] = 1+ X[i]$. <br>\n",
    "&nbsp; Now we can use the inductive hypothesis and write:  <br>\n",
    "&nbsp; $X[i+1] = 1+ 1+max\\{X[j]; j=0,...,j=i-1 | S[j]<S[i]\\}$ <br>\n",
    "&nbsp; If we assume that exist such a j we get: <br>\n",
    "&nbsp; $X[i+1] = 1+max\\{X[j]; j=0,...,j=i | S[j]<S[i+1]\\}$ <br>\n",
    "That prove the formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\phi_k = 1-(\\phi_1 + ...+ \\phi_{k-1}) $"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ADM_HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
